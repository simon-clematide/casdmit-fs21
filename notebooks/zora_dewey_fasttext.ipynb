{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simon-clematide/casdmit-fs21/blob/master/notebooks/zora_dewey_fasttext.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yA0jk-dDThY"
      },
      "source": [
        "# Dewey-Klassifikation mit Zora-Material mit fasttext\n",
        "\n",
        "> Indented block\n",
        "\n",
        "\n",
        "Dieses Notebook demonstriert, wie einfach man ein gutes Klassifikations-Modell mit fastText trainieren kann.\n",
        "Wir arbeiten mit der fasttext Python-Bibliothek.\n",
        "Aus Effizienzgründen arbeiten wir hier mit einem kleineren Trainingsdatensatz."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Das Python fasttext und spaCy Package installieren\n",
        "Aktuellere Version hat [Bug](https://stackoverflow.com/questions/61787119/fasttext-0-9-2-why-is-recall-nan) in der label-spezifischen Evaluationsfunktion korrigiert "
      ],
      "metadata": {
        "id": "cawmGkN5EGOD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-FhvBZODThd"
      },
      "outputs": [],
      "source": [
        "# ! pip install fasttext # schnell zu installieren, aber hat Bug bei test_label()\n",
        "! pip install git+https://github.com/facebookresearch/fastText.git  # braucht mehr Zeit fürs Kompilieren"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install spacy"
      ],
      "metadata": {
        "id": "F5xv5Gu0Dpjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! python3 -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "Tg_fEomTDwWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "nlp.disable_pipes(\"parser\", \"ner\")"
      ],
      "metadata": {
        "id": "1k9yNADPFoix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ayoKk0DDThf"
      },
      "source": [
        "# Datenset: Zufällig ausgewählte Publikationen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izaArcRJDThf"
      },
      "outputs": [],
      "source": [
        "! curl https://files.ifi.uzh.ch/cl/siclemat/lehre/fs23/bibliosuisse/data/zora-eng-dewey.fasttext.tsv -o zora-eng-dewey.fasttext.tsv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmQL4uuiDThh"
      },
      "source": [
        "### Format des Datensets \n",
        " - Pro tabulator-separierte Zeile gibt es 2 Spalten\n",
        " - Spalte 1: [Dewey-Labels](https://en.wikipedia.org/wiki/List_of_Dewey_Decimal_classes)\n",
        " - Spalte 2: Titel und Abstract untokenisiert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBRIuu9LDThh"
      },
      "outputs": [],
      "source": [
        "! head -n 10 zora-eng-dewey.fasttext.tsv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Statistiken zum Datenset"
      ],
      "metadata": {
        "id": "z6MnzVp7E_sB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lL2yiOGADThi"
      },
      "outputs": [],
      "source": [
        "! wc -l zora-eng-dewey.fasttext.tsv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6eXxVbBDThj"
      },
      "outputs": [],
      "source": [
        "!  cut -f 1 < zora-eng-dewey.fasttext.tsv | sort | uniq -c | sort -rn "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatize_tsv(inputfile, outputfile, spacy_nlp, limit=999999):\n",
        "    \"\"\"Write tokenized and lemmatized version of data set\"\"\"\n",
        "\n",
        "    with open(outputfile,\"w\",encoding=\"utf-8\")as output:\n",
        "        with open(inputfile,\"r\",encoding=\"utf-8\") as input:\n",
        "            for i,line in enumerate(input):\n",
        "                labels, text = line.strip().split(\"\\t\")\n",
        "                doc = nlp(text)\n",
        "                print(labels,' '.join(token.lemma_ for token in doc).lower(),sep=\"\\t\",file=output)\n",
        "                if i > limit:\n",
        "                    break\n",
        "                if i % 100 == 0:\n",
        "                    print(f\"Processed {i} records\")\n"
      ],
      "metadata": {
        "id": "OUqaKnqKFGl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download precomputed lemmatized data\n",
        "#! curl https://files.ifi.uzh.ch/cl/siclemat/lehre/fs23/bibliosuisse/data/zora-eng-dewey.lemmatized.fasttext.tsv -o zora-eng-dewey.lemmatized.fasttext.tsv"
      ],
      "metadata": {
        "id": "UOMKmQo01b6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatize_tsv(\"zora-eng-dewey.fasttext.tsv\",\"zora-eng-dewey-10.lemmatized.fasttext.tsv\",nlp,limit=10)"
      ],
      "metadata": {
        "id": "6N2Y7-UEGwuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! head zora-eng-dewey-10.lemmatized.fasttext.tsv"
      ],
      "metadata": {
        "id": "X7tvPloV1dXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatize_tsv(\"zora-eng-dewey.fasttext.tsv\",\"zora-eng-dewey.lemmatized.fasttext.tsv\",nlp)"
      ],
      "metadata": {
        "id": "-1TNlSROMByF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! head zora-eng-dewey.lemmatized.fasttext.tsv"
      ],
      "metadata": {
        "id": "1MehmfPOcEhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multilabel2singlelabel(inputfile, outputfile):\n",
        "    \"\"\"Reduce labels to the first label mentioned\"\"\"\n",
        "    with open(outputfile,\"w\",encoding=\"utf-8\")as output:\n",
        "        with open(inputfile,\"r\",encoding=\"utf-8\") as input:\n",
        "            for i,line in enumerate(input):\n",
        "                labels, text = line.strip().split(\"\\t\")\n",
        "                label = labels.split(\" \")[0]\n",
        "                print(label, text, sep=\"\\t\",file=output)\n"
      ],
      "metadata": {
        "id": "k16i-91ewZo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multilabel2singlelabel(\"zora-eng-dewey.lemmatized.fasttext.tsv\",\"zora-eng-dewey.lemmatized.fasttext.single.tsv\")"
      ],
      "metadata": {
        "id": "jgGV1zOCxBQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! head zora-eng-dewey.lemmatized.fasttext.single.tsv"
      ],
      "metadata": {
        "id": "Tuhq39iqxRzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOH-9FLFDThk"
      },
      "source": [
        "## Aufteilen der Daten in Trainings- und Testdaten\n",
        "Erstellen von Training und Testdaten (Originaldaten sind zufällig geordnet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kq5ZOladDThk"
      },
      "outputs": [],
      "source": [
        "! head -n 9000 < zora-eng-dewey.lemmatized.fasttext.tsv > zora-eng-dewey.lemmatized.fasttext.train.tsv\n",
        "! tail -n 1000 < zora-eng-dewey.lemmatized.fasttext.tsv > zora-eng-dewey.lemmatized.fasttext.test.tsv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# optional erzeuge single label Daten\n",
        "! head -n 9000 < zora-eng-dewey.lemmatized.fasttext.single.tsv > zora-eng-dewey.lemmatized.fasttext.train.tsv\n",
        "! tail -n 1000 < zora-eng-dewey.lemmatized.fasttext.single.tsv > zora-eng-dewey.lemmatized.fasttext.test.tsv"
      ],
      "metadata": {
        "id": "Mc_28Qrkxf6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! echo TRAINING DATA STATISTICS\n",
        "! cut -f 1 < zora-eng-dewey.lemmatized.fasttext.train.tsv | sort | uniq -c | sort -rn |head\n",
        "! echo TEST DATA STATISTICS\n",
        "! cut -f 1 < zora-eng-dewey.lemmatized.fasttext.test.tsv | sort | uniq -c | sort -rn |head"
      ],
      "metadata": {
        "id": "cM69z1KmHaEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7efDuWdOwMX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4_msKJSDTho"
      },
      "source": [
        "# Trainieren von Modell mit Python-Package\n",
        " - Dokumentation siehe https://fasttext.cc/docs/en/python-module.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40vFiCAQDTho"
      },
      "outputs": [],
      "source": [
        "import fasttext"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Word Embeddings](https://fasttext.cc/docs/en/pretrained-vectors.html) auf Wikipedia trainiert und wegen Speichergründen von mir auf 50 Dimensionen reduziert (Text-Format ist notwendig für supervisierte Klassifikation)"
      ],
      "metadata": {
        "id": "bD8354rOdKn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! test -e wiki.en.50.vec || curl https://files.ifi.uzh.ch/cl/siclemat/lehre/fs23/bibliosuisse/data/wiki.en.50.vec -o wiki.en.50.vec"
      ],
      "metadata": {
        "id": "QVDc2kQlcuYK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKtx28_CDTho"
      },
      "outputs": [],
      "source": [
        "# dauert ca. 40 Sekunden mit diesen Einstellungen\n",
        "model = fasttext.train_supervised(\n",
        "    input='zora-eng-dewey.lemmatized.fasttext.train.tsv', \n",
        "    pretrainedVectors=\"wiki.en.50.vec\", # vortrainierte word embeddings\n",
        "    epoch=10,  # Wie oft werden die Trainingsdaten benutzt\n",
        "    minn=5,    # Minimal Subword-Länge in Buchstaben  \n",
        "    maxn=5,    # Maximale Subword-Länge in Buchstaben \n",
        "    dim=50,    # Dimensionalität der Vektoren für die Repräsentation der Wörter und Subwords (muss gleich wie pretrainedVectors sein)\n",
        "    lr=1,      # Learning Rate (Lernrate): Wie stark wird ein Fehler bestraft? \n",
        "    ws=10,\n",
        "    verbose = True\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspizieren des gelernten Modells"
      ],
      "metadata": {
        "id": "IQuLDqMdPEsy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Welche Labels/Klassen kennt das Modell?"
      ],
      "metadata": {
        "id": "j2YSVXdZP9yO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aq7TtoJTDThp"
      },
      "outputs": [],
      "source": [
        "print(model.labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Einen String klassifizieren und die Wahrscheinlichkeitsverteilung über allen möglichen Dewey erhalten:"
      ],
      "metadata": {
        "id": "gUHd0gFMQGzs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "leavip9EDThp"
      },
      "outputs": [],
      "source": [
        "result = model.predict(\"interpersonal problems associate with multidimensional personality questionnaire traits in woman \",  \n",
        "              k=5  # Gib die 5 besten Klassen aus\n",
        "              )\n",
        "for label,prob in zip(*result):\n",
        "    print(label, round(prob,3))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Systematisches Testen des trainierten Models auf Testdaten:\n",
        " - k: Maximale Anzahl vorgeschlagener Labels\n",
        " - threshold: Minimale Wahrscheinlichkeit eine Labels, damit es als vorhergesagt gilt"
      ],
      "metadata": {
        "id": "C5TbsDPQNEdx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dM860ZY7DThp"
      },
      "outputs": [],
      "source": [
        "model.test(\"zora-eng-dewey.lemmatized.fasttext.test.tsv\",k=3,threshold=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F3PRvvWk5_us"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTs98FNoDThq"
      },
      "outputs": [],
      "source": [
        "def print_results(N, p, r):\n",
        "    \"Pretty print performance: N=Number of Samples, P/R@1=Precision/Recall of best prediction Acc=Accuracy \"\n",
        "    print(f\"N\\t{N}\")\n",
        "    print(f\"P@k\\t{p:.2f}\")\n",
        "    print(f\"R@k\\t{r:.2f}\")\n",
        "    print(f\"Acc\\t{r:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qqQXM9zDThq"
      },
      "outputs": [],
      "source": [
        "print_results(*model.test(\"zora-eng-dewey.lemmatized.fasttext.test.tsv\",k=3,threshold=0.25))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Detaillierte Evaluation zu jedem einzelnen Label:\n",
        " - Precision: Anteil korrekter Klassifikationen einer Klasse\n",
        " - Recall: Anteil korrekt klassifizierter Elemente einer Klasse\n",
        " - f1score: Harmonisches Mittel von Precision und Recall"
      ],
      "metadata": {
        "id": "5bAUu9DuVEXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = model.test_label('zora-eng-dewey.lemmatized.fasttext.test.tsv',k=3, threshold=0.35)\n",
        "sorted_data = sorted(data.items(), key=lambda x: x[1]['f1score'], reverse=True)\n",
        "print(sorted_data)\n",
        "for label, perf in sorted_data:\n",
        "    print(label, perf)"
      ],
      "metadata": {
        "id": "aVaCjOcbSWVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZcTfumNDThn"
      },
      "source": [
        "## Vorhersagen und Wahrheit anzeigen"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh"
      ],
      "metadata": {
        "id": "dj0LMb-klIRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "470gKPX_DTho"
      },
      "outputs": [],
      "source": [
        "test_data = []\n",
        "with open(\"zora-eng-dewey.lemmatized.fasttext.test.tsv\", mode=\"r\",encoding=\"utf-8\") as testfile:\n",
        "    for line in testfile:\n",
        "        test_data.append(line.strip().split(\"\\t\"))\n",
        "test_data[:3]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "confusion_matrix = Counter()\n",
        "\n",
        "# If given a list of strings, it will return a list of results as usually received for a single line of text.\n",
        "predictions,probs = model.predict([text for _,text in test_data], k=3, threshold=0.25)\n",
        "\n",
        "for i,preds in enumerate(predictions):\n",
        "    labels = \" \".join(sorted(preds)).replace('__label__','')\n",
        "    if not labels:\n",
        "        labels = '???'\n",
        "    confusion_matrix[(test_data[i][0].replace('__label__',''),labels)] += 1\n",
        "\n",
        "# korrekte \n",
        "print(\"CORRECT PREDICTIONS\")\n",
        "for (correct, predicted), count in confusion_matrix.most_common():\n",
        "    if correct == predicted:\n",
        "        print(\"TRUTH\",correct, \"SYSTEM\",predicted, \"COUNT\",count)\n",
        "\n",
        "# falsche \n",
        "print(\"\\n\\nWRONG PREDICTIONS\")\n",
        "for (correct, predicted), count in confusion_matrix.most_common():\n",
        "    if correct != predicted:\n",
        "        print(\"TRUTH\",correct, \"SYSTEM\",predicted, \"COUNT\",count)"
      ],
      "metadata": {
        "id": "RIx-qm5-bUV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_HB89vqDThm"
      },
      "source": [
        "# Verbessern des Modells\n",
        "Verbessern des Modells: Z.B. mehr Epochen, mehr Dimensionen, längere Buchstaben-N-Gramme, ...\n",
        "\n",
        "Wichtigste Parameter:\n",
        "```\n",
        "   epoch N  # Beim Lernen wird das ganze Trainingsset N mal benutzt. Beeinflusst die Dauer des Trainings linear!\n",
        "   dim N    # Länge der gelernten Vektoren für Wörter und Buchstaben-N-Gramme\n",
        "   lr 0.N   # Initiale Lernrate: Bestimmt, wie stark die Vektoren verändert werden, wenn Fehler passieren. Während des Lernens wird die Lernrate immer kleiner.\n",
        "   mmin N   # Minimale Länge der Subwords, d.h. Buchstaben-N-Gramme\n",
        "   maxn N   # Maximale Länger der Subwords, d.h. Buchstaben-N-Gramme (falls N=0, werden keine Subwords benutzt, nur Wörter)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = fasttext.train_supervised(\n",
        "    input='zora-eng-dewey.lemmatized.fasttext.train.tsv', \n",
        "    pretrainedVectors=\"wiki.en.50.vec\", # vortrainierte word embeddings, können weggelassen werden\n",
        "    epoch=20,  # Wie oft werden die Trainingsdaten benutzt\n",
        "    minn=5,    # Minimal Subword-Länge in Buchstaben  \n",
        "    maxn=5,    # Maximale Subword-Länge in Buchstaben \n",
        "    dim=50,    # Dimensionalität der Vektoren für die Repräsentation der Wörter und Subwords (muss gleich wie pretrainedVectors sein)\n",
        "    lr=1,      # Learning Rate (Lernrate): Wie stark wird ein Fehler bestraft? \n",
        "    )\n",
        "print_results(*model.test(\"zora-eng-dewey.lemmatized.fasttext.test.tsv\"))\n",
        "model.test_label('zora-eng-dewey.lemmatized.fasttext.test.tsv',k=3, threshold=0.25)"
      ],
      "metadata": {
        "id": "2n7rBpwhWynE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOyEz_nQDThq"
      },
      "source": [
        "# Anhang: Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! test -e wiki.en.50.bin || curl https://files.ifi.uzh.ch/cl/siclemat/lehre/fs23/bibliosuisse/data/wiki.en.50.bin -o wiki.en.50.bin"
      ],
      "metadata": {
        "id": "K6FK5AGU3Jp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_model = fasttext.load_model('wiki.en.50.bin')"
      ],
      "metadata": {
        "id": "ahIDUGrq3VkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_model.get_nearest_neighbors('disease')"
      ],
      "metadata": {
        "id": "gxR9wuRs3rqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A is to B, like ? is to C model.get_analogies(A,B,C)"
      ],
      "metadata": {
        "id": "zPtfEwxL7hD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_model.get_analogies('man','woman','queen')"
      ],
      "metadata": {
        "id": "xJsjpxBy38ep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to store the 400000 most frequent words in a smaller text format that is usable for supervised training."
      ],
      "metadata": {
        "id": "3ShKWsug7s9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=full_model\n",
        "# Store only the 100,000 most frequent words\n",
        "max_words = 400000\n",
        "words = model.words[:max_words]\n",
        "vectors = [model[word] for word in words]\n",
        "\n",
        "# Save the subset of words and vectors to a text file\n",
        "with open(\"model_subset.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    # Write the header with the vocabulary size and vector dimensionality\n",
        "    f.write(f\"{max_words} {model.get_dimension()}\\n\")\n",
        "\n",
        "    # Write the vectors for each word\n",
        "    for word, vector in zip(words, vectors):\n",
        "        vector_str = \" \".join([f\"{x:.6f}\" for x in vector])\n",
        "        f.write(f\"{word} {vector_str}\\n\")\n"
      ],
      "metadata": {
        "id": "x0-2yl4Ssh2J"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "livereveal": {
      "center": true,
      "embedded": false,
      "enable_chalkboard": true,
      "scroll": true,
      "start_slideshow_at": "selected",
      "theme": "simple",
      "transition": "fade"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}